{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ssyTPUPVO3hz",
        "outputId": "7f9ce7e4-54fa-431d-90a7-34be91f5a53b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.7.22)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.6)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.22.4)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.0)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.8 snuggs-1.4.7\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "!pip install rasterio\n",
        "import rasterio\n",
        "import geopandas\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldxG6R7qO3h2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def read_window(dataset, row, col, width=100, height=100):\n",
        "    # Calculate the upper-left pixel coordinates of the window\n",
        "    ul_col = max(0, col - width // 2)\n",
        "    ul_row = max(0, row - height // 2)\n",
        "\n",
        "    # Calculate the lower-right pixel coordinates of the window\n",
        "    lr_col = min(dataset.shape[1], col + width // 2)\n",
        "    lr_row = min(dataset.shape[0], row + height // 2)\n",
        "\n",
        "     # Calculate the actual size of the window\n",
        "    actual_width = lr_col - ul_col\n",
        "    actual_height = lr_row - ul_row\n",
        "\n",
        "    # Read the data within the window\n",
        "\n",
        "    data = dataset[ul_row:lr_row, ul_col:lr_col]\n",
        "\n",
        "    if actual_width < width or actual_height < height:\n",
        "        pad_width = width - actual_width\n",
        "        edge_width = pad_width // 2\n",
        "        pad_height = height - actual_height\n",
        "        edge_heigth = pad_height // 2\n",
        "        data = np.pad(data, ((edge_heigth, pad_height-edge_heigth), (edge_width, pad_width-edge_width)), mode='mean')\n",
        "\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEF3Y-J1O3h3"
      },
      "outputs": [],
      "source": [
        "class extractWindows():\n",
        "    def __init__(self, feature_readers, target_reader, add_feat):\n",
        "        self.num_feat = len(feature_readers)\n",
        "        self.feature_readers = feature_readers\n",
        "        self.target_reader = target_reader\n",
        "        self.add_feat = add_feat\n",
        "\n",
        "    def __getFeatures__(self, row, col):\n",
        "    #get for each feature the corresponding window \"\n",
        "        features = []\n",
        "        for i in range(self.num_feat):\n",
        "            data_feat = read_window(self.feature_readers[i], row, col)\n",
        "\n",
        "            features.append(data_feat)\n",
        "\n",
        "        features = np.array(features)\n",
        "\n",
        "        point_feat = []\n",
        "        window=((row, row+1), (col, col+1))\n",
        "        for lay in self.add_feat:\n",
        "\n",
        "            p_f = lay.read(1, window = window)\n",
        "\n",
        "\n",
        "            point_feat.append(p_f[0])\n",
        "\n",
        "        return features, np.array(point_feat)\n",
        "\n",
        "    def __getTarget__(self, row, col):\n",
        "\n",
        "        window=((row, row+1), (col, col+1))\n",
        "\n",
        "        target = self.target_reader.read(1, window = window)\n",
        "\n",
        "        return target\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Mbvw0LhSBWu",
        "outputId": "9148d854-ce1d-49c0-a8d3-9953440f8b10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Archive:  drive/MyDrive/Landslides_data/Features.zip\n",
            "  inflating: aspect.tif              \n",
            "  inflating: curvature.tif           \n",
            "  inflating: dtm.tif                 \n",
            "  inflating: geo_faults.tif          \n",
            "  inflating: land_cover_raster.tif   \n",
            "  inflating: prec_90.tif             \n",
            "  inflating: prec_avr.tif            \n",
            "  inflating: rivers.tif              \n",
            "  inflating: roads.tif               \n",
            "  inflating: slope_rad.tif           \n",
            "  inflating: train_raster.tif        \n",
            "  inflating: twi.tif                 \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "path_drive = r'drive/MyDrive/Landslides_data/'\n",
        "#path = r'datasets/'\n",
        "\n",
        "!unzip drive/MyDrive/Landslides_data/Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oZIWVAcO3h4"
      },
      "outputs": [],
      "source": [
        "path = ''\n",
        "elevation = rasterio.open(path + 'dtm.tif')\n",
        "elevation = elevation.read(1)\n",
        "twi = rasterio.open(path + 'twi.tif')\n",
        "twi = twi.read(1)\n",
        "slope_rad = rasterio.open(path + 'slope_rad.tif')\n",
        "slope_rad = slope_rad.read(1)\n",
        "aspect = rasterio.open(path + 'aspect.tif')\n",
        "aspect = aspect.read(1)\n",
        "curvature = rasterio.open(path + 'curvature.tif')\n",
        "curvature = curvature.read(1)\n",
        "\n",
        "rain_90 = rasterio.open(path +'prec_90.tif')\n",
        "rain_avr = rasterio.open(path +'prec_avr.tif')\n",
        "\n",
        "land_cover = rasterio.open(path +'land_cover_raster.tif')\n",
        "land_cover = land_cover.read(1)\n",
        "geo_faults = rasterio.open(path +'geo_faults.tif')\n",
        "roads = rasterio.open(path +'roads.tif')\n",
        "rivers = rasterio.open(path +'rivers.tif')\n",
        "\n",
        "\n",
        "\n",
        "target = rasterio.open(path +'train_raster.tif')\n",
        "\n",
        "feature_list = [elevation, twi, slope_rad, aspect, curvature, land_cover]\n",
        "                #rain_90, rain_avr, land_cover, geo_faults, roads, rivers]\n",
        "add_feat = [rain_90, rain_avr, geo_faults, roads, rivers]\n",
        "#reproduce\n",
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "np.random.seed(random_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Nxkc_ag3O3h6"
      },
      "source": [
        "### create stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlFumgEHO3h8"
      },
      "outputs": [],
      "source": [
        "#RUN THIS ONCE TO CREATE DF\n",
        "\n",
        "\"\"\"\n",
        "how the stats are calculated\n",
        "el = elevation.read(1)\n",
        "mask = (el != 0) #filter out all cells with no data, approx lowest point in region is above 0\n",
        "el = None\n",
        "\n",
        "columns = ['elevation', 'twi', 'slope_rad', 'aspect', 'curvature', 'rain_90', 'rain_avr',\n",
        "           'land_cover', 'geo_faults', 'roads', 'rivers']\n",
        "\n",
        "index = ['mean', 'std']\n",
        "stats_df = pd.DataFrame(index = index, columns = columns)\n",
        "\n",
        "for i in range(len(feature_list)):\n",
        "    col = columns[i]\n",
        "\n",
        "    layer = feature_list[i].read(1)\n",
        "    filtered_layer = layer[mask]\n",
        "    mean = filtered_layer.mean()\n",
        "    std = filtered_layer.std()\n",
        "\n",
        "    stats_df[col] = [mean, std]\n",
        "\n",
        "\n",
        "\n",
        "stats_df.to_csv(r'datasets/stats.csv')\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "stats_df = pd.read_csv(path_drive +'stats.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNwo5SrQO3h-"
      },
      "outputs": [],
      "source": [
        "window_Extracter = extractWindows(feature_readers=feature_list,\n",
        "                                  target_reader=target, add_feat = add_feat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JNo3FRTO3h-"
      },
      "outputs": [],
      "source": [
        "class MapData(Dataset):\n",
        "    def __init__(self, window_extracter, rows, cols):\n",
        "        self.extracter = window_extracter\n",
        "        self.rows = rows\n",
        "        self.cols = cols\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.rows[index]\n",
        "        col = self.cols[index]\n",
        "\n",
        "        X, X2 = self.extracter.__getFeatures__(row, col)\n",
        "        Y = self.extracter.__getTarget__(row, col)\n",
        "\n",
        "\n",
        "        X = torch.tensor(X, dtype=torch.float32)\n",
        "        X2 = torch.tensor(X2,dtype=torch.float32 )\n",
        "        Y = torch.tensor(Y, dtype=torch.float32)\n",
        "\n",
        "        return X, X2, Y[0]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.rows) #same amount of data points\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwzZUSTQO3h_"
      },
      "outputs": [],
      "source": [
        "train_row_cols = pd.read_csv(path_drive + 'row_col_target.csv')\n",
        "#train_row_cols = train_row_cols.sample(frac=0.3, random_state = 42)\n",
        "\n",
        "#count entries\n",
        "counts  = train_row_cols['target'].to_frame().value_counts()\n",
        "smallest_size = counts.iloc[-1]\n",
        "\n",
        "\n",
        "# original subsets for each class\n",
        "subsets = []\n",
        "for prob in range(2):\n",
        "    filtered = train_row_cols[train_row_cols['target'] == prob]\n",
        "    subsets.append(filtered)\n",
        "\n",
        "train_row_cols = None\n",
        "# under-sample each subset\n",
        "undersampled_subset = []\n",
        "for i in subsets:\n",
        "    shuffled_i = i.sample(frac = 1) #so data is randomly shuffles\n",
        "    i = shuffled_i.iloc[:smallest_size].copy()\n",
        "    undersampled_subset.append(i)\n",
        "\n",
        "# concatenate the seven under-sampled subsets, and shuffle the data\n",
        "undersampled_df = pd.concat(undersampled_subset)\n",
        "undersampled_df = undersampled_df.sample(frac=1)\n",
        "\n",
        "\n",
        "rows = undersampled_df['row'].values\n",
        "cols = undersampled_df['col'].values\n",
        "\n",
        "undersampled_df = None\n",
        "\n",
        "\n",
        "mean = stats_df.iloc[0].values[1:].astype('float32')\n",
        "std = stats_df.iloc[1].values[1:].astype('float32')\n",
        "\n",
        "t_mean = np.concatenate((mean[:5], [mean[7]]))\n",
        "t_std =  np.concatenate((std[:5], [std[7]]))\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((100,100)),\n",
        "    transforms.RandomHorizontalFlip(p=0.4),\n",
        "    transforms.RandomVerticalFlip(p=0.25),\n",
        "    transforms.Normalize(mean=t_mean, std =t_std)\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-YnbctcOf0B"
      },
      "outputs": [],
      "source": [
        "map = MapData(window_Extracter, rows, cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "n8T41JyBO3iA"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daTLLLcdO3iA"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.0001\n",
        "batch_size = 64\n",
        "amount_train = 0.7\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGfcmFMNO3iB"
      },
      "outputs": [],
      "source": [
        "training_data_size = len(rows)\n",
        "train_size = int(amount_train*training_data_size)\n",
        "test_size = training_data_size - train_size\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(map, [train_size, test_size])\n",
        "\n",
        "data_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "data_test = DataLoader(test_dataset, batch_size=batch_size, shuffle =False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NukltnbRO3iB"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(6, 16, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(25*25*32, 512)\n",
        "        self.fc2 = nn.Linear(512, 32)\n",
        "        self.fc3 = nn.Linear(32+5, 32)\n",
        "        self.fc4 = nn.Linear(32, 1)\n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout(p = 0.5)\n",
        "\n",
        "    def forward(self, X, X2):\n",
        "\n",
        "        X = self.pool(F.relu(self.conv1(X))) #11 x 100 x 100 input, out 16 x 50 x 50\n",
        "        X = self.pool(F.relu(self.conv2(X))) # in: 16 x 50 x 50 , out 36 x 25 x 25\n",
        "\n",
        "\n",
        "        X = X.view(-1, 25*25*32)\n",
        "        X = F.relu(self.fc1(X))\n",
        "        X = self.dropout(X)\n",
        "\n",
        "        X = F.relu(self.fc2(X))\n",
        "        X = self.dropout(X)\n",
        "\n",
        "        X = torch.cat((X, X2.view(-1, 5)), dim=1)\n",
        "        X = self.dropout(X)\n",
        "\n",
        "        X = F.relu(self.fc3(X))\n",
        "\n",
        "        X = torch.sigmoid(self.fc4(X))\n",
        "\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4lu9EwdO3iC"
      },
      "outputs": [],
      "source": [
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "CNN_DNN = ConvNet().to(device)\n",
        "loss_fn = torch.nn.BCELoss()\n",
        "loss_fn = loss_fn.to(device)\n",
        "optimizer = torch.optim.Adam(CNN_DNN.parameters(), lr = learning_rate)\n",
        "epochs = 3\n",
        "\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P__XC0bDO3iC"
      },
      "outputs": [],
      "source": [
        "def train(epochs, CNN, loss_fn, optimizer,\n",
        "          data_train, data_test, transformer, scheduler):\n",
        "    print('Starting training..')\n",
        "    for e in range(0, epochs):\n",
        "        print('='*20)\n",
        "        print(f'Starting epoch {e + 1}/{epochs}')\n",
        "        print('='*20)\n",
        "\n",
        "        train_loss = 0.\n",
        "        val_loss = 0.\n",
        "\n",
        "        CNN.train()\n",
        "        # set model to training phase\n",
        "\n",
        "        for train_step, (images,X2, labels) in enumerate(data_train):\n",
        "\n",
        "            images = images.to(device)\n",
        "            images = transformer(images)\n",
        "            X2 = X2.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # set the gradients to zero (you can do so by accessing the optimizer)\n",
        "            optimizer.zero_grad()\n",
        "            # compute outputs\n",
        "            output = CNN(images, X2).to(device)\n",
        "\n",
        "\n",
        "            # compute loss  (you have defined the loss_fn above!)\n",
        "            loss = loss_fn(output, labels)\n",
        "\n",
        "            #  use backward() so that the whole graph is differentiated w.r.t. the loss\n",
        "            loss.backward()\n",
        "            # performs a parameter update based on the current gradient (Note: you need to do it through the optimizer)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            if train_step % 1000 == 0:\n",
        "\n",
        "                if train_step % 2000 == 0 and train_step > 0:\n",
        "                  scheduler.step()\n",
        "\n",
        "                print('Evaluating at step', train_step)\n",
        "\n",
        "                accuracy = 0\n",
        "\n",
        "                CNN.eval()          # set model to eval phase\n",
        "\n",
        "                for val_step, (images, X2, labels) in enumerate(data_test):\n",
        "                    images = images.to(device)\n",
        "                    images = transformer(images)\n",
        "                    X2 = X2.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    outputs = CNN(images, X2).to(device)\n",
        "                             # compute outputs\n",
        "\n",
        "                    loss = loss_fn(outputs, labels)\n",
        "                    loss = loss.to(device)\n",
        "                        # compute loss\n",
        "                    val_loss += loss.item()\n",
        "\n",
        "                    preds = (outputs > 0.5).float()\n",
        "                    accuracy += sum((preds.cpu() == labels.cpu()).numpy())\n",
        "\n",
        "                    if val_step == 500:\n",
        "                      break\n",
        "\n",
        "                val_loss = val_loss\n",
        "                val_loss /= (val_step + 1)\n",
        "                accuracy = accuracy\n",
        "                accuracy = accuracy/(val_step *64)\n",
        "                print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy[0]:.4f}')\n",
        "\n",
        "                CNN.train()\n",
        "\n",
        "\n",
        "\n",
        "        train_loss /= (train_step + 1)\n",
        "\n",
        "        print(f'Training Loss: {train_loss:.4f}')\n",
        "    print('Training complete..')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96H-U1rgO3iD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ebe7c3a-6fba-4092-f19f-465f8e71a847"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training..\n",
            "====================\n",
            "Starting epoch 1/3\n",
            "====================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating at step 0\n",
            "Validation Loss: 0.6926, Accuracy: 0.4963\n",
            "Evaluating at step 1000\n",
            "Validation Loss: 0.3914, Accuracy: 0.8310\n",
            "Evaluating at step 2000\n",
            "Validation Loss: 0.3678, Accuracy: 0.8415\n",
            "Evaluating at step 3000\n",
            "Validation Loss: 0.3438, Accuracy: 0.8563\n",
            "Evaluating at step 4000\n",
            "Validation Loss: 0.3494, Accuracy: 0.8546\n",
            "Evaluating at step 5000\n",
            "Validation Loss: 0.3474, Accuracy: 0.8595\n",
            "Evaluating at step 6000\n",
            "Validation Loss: 0.3482, Accuracy: 0.8602\n",
            "Evaluating at step 7000\n",
            "Validation Loss: 0.3564, Accuracy: 0.8610\n",
            "Evaluating at step 8000\n",
            "Validation Loss: 0.3464, Accuracy: 0.8614\n",
            "Evaluating at step 9000\n",
            "Validation Loss: 0.3530, Accuracy: 0.8640\n",
            "Evaluating at step 10000\n",
            "Validation Loss: 0.3570, Accuracy: 0.8645\n",
            "Evaluating at step 11000\n",
            "Validation Loss: 0.3554, Accuracy: 0.8648\n",
            "Evaluating at step 12000\n",
            "Validation Loss: 0.3493, Accuracy: 0.8661\n",
            "Evaluating at step 13000\n",
            "Validation Loss: 0.3493, Accuracy: 0.8677\n",
            "Evaluating at step 14000\n",
            "Validation Loss: 0.3519, Accuracy: 0.8656\n",
            "Evaluating at step 15000\n",
            "Validation Loss: 0.3524, Accuracy: 0.8683\n",
            "Evaluating at step 16000\n",
            "Validation Loss: 0.3517, Accuracy: 0.8687\n",
            "Evaluating at step 17000\n",
            "Validation Loss: 0.3500, Accuracy: 0.8692\n",
            "Evaluating at step 18000\n",
            "Validation Loss: 0.3556, Accuracy: 0.8677\n",
            "Evaluating at step 19000\n",
            "Validation Loss: 0.3517, Accuracy: 0.8691\n",
            "Evaluating at step 20000\n",
            "Validation Loss: 0.3504, Accuracy: 0.8690\n",
            "Evaluating at step 21000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-faf42f83e991>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train(epochs, CNN_DNN, loss_fn=loss_fn, optimizer=optimizer,\n\u001b[0m\u001b[1;32m      2\u001b[0m       \u001b[0mdata_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       transformer= data_transform, scheduler = scheduler)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-d8be51d67181>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, CNN, loss_fn, optimizer, data_train, data_test, transformer, scheduler)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m# set model to eval phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mval_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-6f5e9c664ee2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextracter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getFeatures__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextracter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getTarget__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-e65a31584e3a>\u001b[0m in \u001b[0;36m__getFeatures__\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlay\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_feat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mp_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train(epochs, CNN_DNN, loss_fn=loss_fn, optimizer=optimizer,\n",
        "      data_train=data_train, data_test=data_test,\n",
        "      transformer= data_transform, scheduler = scheduler)\n",
        "\n",
        "#stopped at step21000"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "opt = torch.optim.Adam(CNN_DNN.parameters(), lr = learning_rate/10)\n",
        "scheduler_2 = lr_scheduler.StepLR(opt, step_size=1, gamma=0.2)\n",
        "\n",
        "train(epochs, CNN_DNN, loss_fn=loss_fn, optimizer=opt,\n",
        "      data_train=data_train, data_test=data_test,\n",
        "      transformer= data_transform, scheduler = scheduler_2)\n",
        "\n",
        "\n",
        "#stop at step 7000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "sWj4feIL1HDS",
        "outputId": "e90cfb68-53e1-4e7e-f180-7047b70947a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training..\n",
            "====================\n",
            "Starting epoch 1/3\n",
            "====================\n",
            "Evaluating at step 0\n",
            "Validation Loss: 0.3001, Accuracy: 0.8727\n",
            "Evaluating at step 1000\n",
            "Validation Loss: 0.2942, Accuracy: 0.8759\n",
            "Evaluating at step 2000\n",
            "Validation Loss: 0.2931, Accuracy: 0.8725\n",
            "Evaluating at step 3000\n",
            "Validation Loss: 0.2903, Accuracy: 0.8777\n",
            "Evaluating at step 4000\n",
            "Validation Loss: 0.2884, Accuracy: 0.8758\n",
            "Evaluating at step 5000\n",
            "Validation Loss: 0.2888, Accuracy: 0.8771\n",
            "Evaluating at step 6000\n",
            "Validation Loss: 0.2885, Accuracy: 0.8767\n",
            "Evaluating at step 7000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1a3e0b57133b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscheduler_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m train(epochs, CNN_DNN, loss_fn=loss_fn, optimizer=opt,\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0mdata_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       transformer= data_transform, scheduler = scheduler_2)\n",
            "\u001b[0;32m<ipython-input-16-d8be51d67181>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, CNN, loss_fn, optimizer, data_train, data_test, transformer, scheduler)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m# set model to eval phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mval_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-6f5e9c664ee2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextracter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getFeatures__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextracter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getTarget__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-e65a31584e3a>\u001b[0m in \u001b[0;36m__getFeatures__\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlay\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_feat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mp_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-wXbwehO3iE"
      },
      "outputs": [],
      "source": [
        "\n",
        "torch.save(CNN_DNN, path_drive + 'cnn_dnn_6.pt')\n",
        "torch.save(CNN_DNN.state_dict(), path_drive + 'cnn_dnn_dict_6.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWOUWK8ktAE-"
      },
      "source": [
        "Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FL9vLszsPVJ"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "test_gpd = gpd.read_file(path_drive + 'Test.gpkg')\n",
        "sample_sub = pd.read_csv(path_drive + 'Test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTiZ3uUDtN0_",
        "outputId": "65b0bf0b-a004-41e1-a1b2-2457aba78e74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40000\n"
          ]
        }
      ],
      "source": [
        "rows_val = []\n",
        "cols_val = []\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((100,100)),\n",
        "    transforms.Normalize(mean=t_mean, std =t_std)\n",
        "])\n",
        "\n",
        "for id, geom in zip(sample_sub['ID'], test_gpd['geometry']):\n",
        "  #geom = test_gpd[test_gpd['ID'] == id]\n",
        "  #geom = geom['geometry'].values[0]\n",
        "  x, y = geom.xy[0][0], geom.xy[1][0]\n",
        "  r, c= roads.index(x,y)\n",
        "\n",
        "  rows_val.append(r)\n",
        "\n",
        "  cols_val.append(c)\n",
        "\n",
        "\n",
        "val_data = MapData(window_Extracter, rows_val, cols_val)\n",
        "\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle =False)\n",
        "\n",
        "target = np.array([])\n",
        "\n",
        "CNN_DNN.eval()\n",
        "\n",
        "for val_step, (images, X2, labels) in enumerate(val_data):\n",
        "                    images = images.to(device)\n",
        "                    images = val_transform(images)\n",
        "                    labels = labels.to(device)\n",
        "                    X2 = X2.to(device)\n",
        "\n",
        "                    outputs = CNN_DNN(images, X2).to(device)\n",
        "                             # compute outputs\n",
        "                    pred = (outputs > 0.5).float()\n",
        "\n",
        "                    t = pred.cpu()\n",
        "\n",
        "                    target = np.append(target, t)\n",
        "\n",
        "print(len(target))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-B2LAtG0ukW-"
      },
      "outputs": [],
      "source": [
        "sample_sub = pd.read_csv(path_drive + 'Test.csv')\n",
        "\n",
        "sample_sub['Target'] = target.astype(np.int8)\n",
        "\n",
        "sample_sub.to_csv(path_drive + 'submission_cnn_6.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyARi1S59CZS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}